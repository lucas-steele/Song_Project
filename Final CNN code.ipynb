{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lms2755\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2   \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as Layers\n",
    "import tensorflow.keras.activations as Actications\n",
    "import tensorflow.keras.models as Models\n",
    "import tensorflow.keras.optimizers as Optimizer\n",
    "import tensorflow.keras.metrics as Metrics\n",
    "import tensorflow.keras.utils as Utils\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "def get_images(directory):\n",
    "    Images = []\n",
    "    Labels = []  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\n",
    "    class_labels = {'buildings': 0,\n",
    "                    'forest' : 1,\n",
    "                    'glacier' : 2,\n",
    "                    'mountain' : 3,\n",
    "                    'sea' : 4,\n",
    "                    'street' : 5\n",
    "                    }\n",
    "    for label in os.listdir(directory):\n",
    "        \n",
    "        for image_file in os.listdir(directory+label): #Extracting the file name of the image from Class Label folder\n",
    "            image = cv2.imread(directory+label+r'/'+image_file) #Reading the image (OpenCV)\n",
    "            image = cv2.resize(image,(150,150)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n",
    "            Images.append(image)\n",
    "            Labels.append(class_labels[label])\n",
    "    \n",
    "    return shuffle(Images,Labels) #Shuffle the dataset you just prepared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images, Labels = get_images('./seg_train/') #Extract the training images from the folders.\n",
    "\n",
    "X_train = np.array(Images, dtype = 'float32') #converting the list of images to numpy array.\n",
    "y_train = np.array(Labels, dtype = 'int32')\n",
    "\n",
    "X_train = X_train/(X_train.max()) #Scale data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_classlabel(class_code):\n",
    "    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
    "    return labels[class_code]\n",
    "\n",
    "f,ax = plt.subplots(5,5) \n",
    "f.subplots_adjust(0,0,3,3)\n",
    "for i in range(0,5,1):\n",
    "    for j in range(0,5,1):\n",
    "        rnd_number = random.randint(0,len(X_train))\n",
    "        ax[i,j].imshow(X_train[rnd_number])\n",
    "        ax[i,j].set_title(get_classlabel(y_train[rnd_number]))\n",
    "        ax[i,j].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images, Labels = get_images('./seg_test/') #Extract the training images from the folders.\n",
    "\n",
    "X_test = np.array(Images, dtype = 'float32') #converting the list of images to numpy array.\n",
    "y_test = np.array(Labels, dtype = 'int32')\n",
    "\n",
    "X_test = X_test/(X_train.max()) #Scale data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), # the nn will learn the good filter to use\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5), # To deal with over fitting\n",
    "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Optimizer.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split = 0.3)\n",
    "score = model.evaluate(X_test, y_test, batch_size=128)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
